{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60dff0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353988da",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 & Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ef46503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2410  images to be resized.\n",
      "2410  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")\n",
    "    print(len(images), \" images to be resized.\")\n",
    "    target_size=(28,28)\n",
    "    \n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c4e3e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601  images to be resized.\n",
      "2601  images resized.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b866f25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1603  images to be resized.\n",
      "1603  images resized.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe81c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 6614 입니다.\n",
      "x_train shape: (6614, 28, 28, 3)\n",
      "y_train shape: (6614,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=6614): #갯수 맞추기\n",
    "    img_size=28 \n",
    "    color=3 #흑백=1,칼라=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img\n",
    "        labels[idx]=2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0 \n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9b412ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAXW0lEQVR4nO2dX2ykZ3XGnzP//H+9u2zW+ydpEmgkFCERmlUUFVRRoaKQm8ANIhcolVCXC5BA4qKIXpDLqCogKiHapaSEioKQABG1aUsakCJuECZKk03SNNs0gWy83sRe/x3bM983pxeeIBP8Psd47JkR7/OTLI/nzPt9r7+ZZ76Z73nPOebuEEL8/lMZ9ASEEP1BYhciEyR2ITJBYhciEyR2ITKh1s+dTU9P+8zMqWTcgvGVSjUZq9X5v1Kv14Nt870zz6LT6fBtW/SfRfHAMaFhPtbCfUfw7a9vtZKxsijo2Ha7TeOdkh93dxLv8HnHLlWP40ncw22nY0vLy2huNHd9UnsSu5ndBeDLAKoA/sHdH2CPn5k5ha/87d8l45UK/6AxPjlBtn2Sjj115jSNj43xN4M2ed00m+t07Gi9QePVavpNDAAM/EVdttOiseBFVzV+zKvBm0FZljT+xIsvJ2MLr71Gx169Mk/jG6trNF60tpKxkrwJAUDZ4vFO8H+X7WD7ZHzRCd7kyMnl77/5j8nYvj/Gm1kVwFcAfADArQDuNbNb97s9IcTh0st39jsAXHL3F929BeA7AO45mGkJIQ6aXsR+FsCvdvz9Sve+38DMzpvZrJnNLi8v97A7IUQvHPrVeHe/4O7n3P3c9PT0Ye9OCJGgF7FfBnDDjr+v794nhBhCehH7zwHcYmY3m1kDwEcAPHww0xJCHDT7tt7cvTCzTwL4D2xbbw+6+zNsTMUMo420DVUGNhGzmNbXuf21shRdL+BfMZg9NlLjtl3kw0dx73A/mnnGjRp/iiO7s7WZtq8AoNls0nh7Kz0+9NGD44LAkjSyviH6vz2IU7MbQCdYW8HmxmLhWDKuJ5/d3R8B8Egv2xBC9ActlxUiEyR2ITJBYhciEyR2ITJBYhciEyR2ITKhr/ns7k698pLlHwPokPzn1RXuTdYCvznKd58+lvbhG2TtwF4oiuD/5tmUqBB3td7j3NqBj74apPeurCwlYxvrUYrqJo2H6xOID09z3RHno7sHKa7B9ktPv5aj/4uNZbnwOrMLkQkSuxCZILELkQkSuxCZILELkQkSuxCZ0F/rreNok5TJMBWUuGtF0Vu6ZBRn6ZgTU+N0bJROGc6NWC0At96KHss1X1tcoPGFBR5fW11Jxtab3HprkeqwQFyK2slxLUte/bXd5vv2oIx1Uey/umwZVZelZajT6MwuRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCb01WeHO7wI8jXp8LS3uRl0zdzY2KDxqDXVlStXkrGRMZ5GOjIyQuNR+i3pVB0S+cGtoFtpVIJ7ZSXtowPABvHxiy2ewloGXnXUSZW91iIffavgcQTHtdNDimvZy5oQ4sHrzC5EJkjsQmSCxC5EJkjsQmSCxC5EJkjsQmSCxC5EJvS9lHSxlfZOo7xv2o82qLfcDuJbpLUwwFtCV2q8jDXLPwZiH77e4EY7K3sc5bOz0t5AfFwin75DMqyLwOsuyyCvO/LZyXPO8sn3EkcZ5NJHLZ2JVx7VNyiwv1LSPYndzF4CsAqgBFC4+7letieEODwO4sz+p+7++gFsRwhxiOg7uxCZ0KvYHcCPzOwXZnZ+tweY2XkzmzWz2WVSj0wIcbj0+jH+Pe5+2cxOAnjUzP7b3R/f+QB3vwDgAgDc8tY/5FcthBCHRk9ndne/3P19FcAPANxxEJMSQhw8+xa7mU2Y2dQbtwG8H8DFg5qYEOJg6eVj/AyAH5jZG9v5Z3f/dzbAO46tjXQOc+izV9J+dkna8wLcfwS4HxyNLwNPtR153YGnW4lSq1kN8siL7sEPBuLa7S3SJyDy8KN42FaZ+PRbgccf9SGIiOrxs+MarY1wpJ9Tdkz2LXZ3fxHAO/c7XgjRX2S9CZEJErsQmSCxC5EJErsQmSCxC5EJ/S0lDQeY5RDZPKQ8b7sT2FtBad8isN6Y7dep8rGNBi81Hdk05RaPszTTyDrrWqfpfQfWXTR3kLlF1lq07ch6Y3OPtl0EKawWvFyi1N9e7FL2Wmbp1DqzC5EJErsQmSCxC5EJErsQmSCxC5EJErsQmSCxC5EJfS4lzX3fyPNl7YfLyDcNjFGr80PBRrM0TiD2dFtBvBqUqmZsbvK2yBFV4+eDqBX2KElbbq6ly3MDQLXKS2hHXvZak5T/DtKpo/UJEc2NJo2zNQJh6u4+x+rMLkQmSOxCZILELkQmSOxCZILELkQmSOxCZILELkQm9DmfnfuAka9aIWPLIB89LEscxEvytlg4z31mufB7oSx4fjPzmyMvOsq17wR+dJu04N6Ok1LSgUdfH+WtrCPYGoEiyBnf3Iw8/P376BHRWGM+e0c+uxDZI7ELkQkSuxCZILELkQkSuxCZILELkQkSuxCZ0FefvSxLLK+uJuORz87aKq9vct9zPcgvbnWC1sbEKu8Yz32u1+s0vtniHr8FufgjI2k/ugLu8a8ur9B4Efj0UQ2CERJvBWsblpfTrxUgrhPQ3Ern8luVn+c8+L/W1vjrKcqH7yWfnZ2jC1LzITyzm9mDZnbVzC7uuO+4mT1qZi90fx+LtiOEGCx7+Rj/DQB3vem+zwJ4zN1vAfBY928hxBATit3dHwew+Ka77wHwUPf2QwA+eLDTEkIcNPu9QDfj7nPd21cAzKQeaGbnzWzWzGZX19f2uTshRK/0fDXet68mJK8ouPsFdz/n7uemJiZ73Z0QYp/sV+zzZnYaALq/rx7clIQQh8F+xf4wgPu6t+8D8MODmY4Q4rAIfXYz+zaA9wI4YWavAPg8gAcAfNfMPgbgZQAf3svOOp0Sa2vp7+3MywaANvHCW0WQV13wnHO2bYD3xI7y2SPfdJWsPQCARoM/TWfOnEnGRkZ4vvr83ByNLy1eo/EjR47Q+LFT6bltNrnPvri+ROOtgvvsW6QOQORk14LjthHku/fSWz6y2dmyiw7x2UOxu/u9idD7orFCiOFBy2WFyASJXYhMkNiFyASJXYhMkNiFyIS+prhapYIGKQ/MUhIBXhbZgzTQqGSyBdYbS0Mt2tx6Gx8fp/GxsTEarwVvyWMkxTVatfgHp8/S+ERjlMYbNZ6+Oz6S/t/XG7yUdKPGS0lPHztO460y/bwsBemzBbFaAWBjg79Wjx49SuMMDzxo2paZpInrzC5EJkjsQmSCxC5EJkjsQmSCxC5EJkjsQmSCxC5EJvTdZx8ZT3vKm0HKInXSg9K/HrRN7pBWtwBv+bwZtO+tkdbBAHD2LPe6t4Iy2VevzCdjdoL7xSdPXEfjk2N8jUAz+N/Z+oYySANdWuJlrusjfA0AKwe9vs7nbUFZ8zJo+Xz51Ss0Tuns32dnqbU6swuRCRK7EJkgsQuRCRK7EJkgsQuRCRK7EJkgsQuRCX312eGODvEIWUtmgJdzjnxytLgv2tzkudXMT97Y4GNff/11Go/KDq+vcb95dWk5GetsBWsXSLllAChb+y+JDAAjR9Je+NYm3/bi4ptbDP4mU9O8jLWRVtnR+oDRySkarwd5/pUqz8XnpaS5z85KN1Qq6fO3zuxCZILELkQmSOxCZILELkQmSOxCZILELkQmSOxCZEJffXYH0Ca1vDsdnnvNPEQHH8v2C/Ca9ABQkJbPFuTSR/HlpSUa39hYp/GpqbQnfPw4r60e+eTRczJz3clg++lYJTguI6QePgCcvG6Gxmtj6fEL17iHb3XeZ6Ba5fXym01el5556dFzYmwsWW8SntnN7EEzu2pmF3fcd7+ZXTazJ7s/d0fbEUIMlr18jP8GgLt2uf9L7n5b9+eRg52WEOKgCcXu7o8D4J95hBBDTy8X6D5pZk91P+YfSz3IzM6b2ayZza6tr/WwOyFEL+xX7F8F8DYAtwGYA/CF1APd/YK7n3P3c5NBk0EhxOGxL7G7+7y7l+7eAfA1AHcc7LSEEAfNvsRuZqd3/PkhABdTjxVCDAehz25m3wbwXgAnzOwVAJ8H8F4zuw3b1vlLAD6+l51VKgBrVf5/L71Cx586c1MytniNXw+oVpOXFQAA9QbPX15//Wp628YPY9Hi+ehbUU54hfvN1VZ6DcCpKf7VqWgu0Xirw/3icpHHj42mj/sfv/16Ora58Esa77TSefwAcOLGtydji7M8n/2dt7+Dxl974ika90q6PwIAVDvp86w5rzFgHbLmA2kPPhS7u9+7y91fj8YJIYYLLZcVIhMkdiEyQWIXIhMkdiEyQWIXIhP6W0oaPN2TtfcFeJppVI55vMFb8Lrz8Wz7gfMWzq0alNBGhVsxkyPpCbBW0wAwNsZLIhv43MuCb//KfLqd9PEZnqJ6++230/h80Hb50qVLyVh0XCYmJmh8Jpj78wvP03idtPGuBqWka0FqcAqd2YXIBIldiEyQ2IXIBIldiEyQ2IXIBIldiEyQ2IXIhD6XknbadjkqHczKPW9ubtKxU9Pcm+yQtMHtfae3X6twD7/jfNudDp9b0eFlrmu1tFe+tMxTUKfPnKDxSnBc1tvcrz5+PL19J+mYAFAL1l0g8NknJ9PpvadOnaJjr127RuNrazylOloz0iDn2XpwDq5V08dNLZuFEBK7ELkgsQuRCRK7EJkgsQuRCRK7EJkgsQuRCX312TudDtbXefthBvPSo5bLCHKA2wUf3yZ52x3n6wPMeL56pcZ9eiuD/OVKOr64yNv0nZk5yjdd5ecDq/CXUIu0fD4yyXPGW23u8U8eOcLHb6Zz8efmX6Vjl9f5uo3REV4q2oIW4mWZfk14sK6iTcKsxbbO7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkQl999rIoaZ7wRovXKC/KtB/tFe5lO3jt9a2tDRoH8U09aLFblNw3JdZouG+ArzHwgh/T5haf2/goXwMwMsFbQteK9Plki7SaBoCVNb4mY/wEz8V/mbR8juof3HjzW2h86RqvEzA1xVuAl5vp415s8hoBnRaJk/bf4ZndzG4ws5+Y2bNm9oyZfap7/3Eze9TMXuj+5g3QhRADZS8f4wsAn3H3WwHcCeATZnYrgM8CeMzdbwHwWPdvIcSQEord3efc/Ynu7VUAzwE4C+AeAA91H/YQgA8e0hyFEAfA73SBzsxuAvAuAD8DMOPuc93QFQC7Nr8ys/NmNmtms+tNXjNMCHF47FnsZjYJ4HsAPu3uKztj7u7A7t0J3f2Cu59z93MT4+M9TVYIsX/2JHYzq2Nb6N9y9+937543s9Pd+GkAVw9nikKIgyC03my7x/LXATzn7l/cEXoYwH0AHuj+/mG0raIssXBtORmvBOmSDZJWOB58aigCC2pjg9s8NZKG6ojKUHMrpRa0ZI7KOa+sp625E8f4cdkKUoNHR/n48UluMY1V0mWu5xd4+m3R4cdlZJS3m15dTdtjN910Ex1755130vijP/oxjVdG6jRekBTXciOw3ohX66T991589ncD+CiAp83sye59n8O2yL9rZh8D8DKAD+9hW0KIARGK3d1/CiSr+b/vYKcjhDgstFxWiEyQ2IXIBIldiEyQ2IXIBIldiEzofynpjfSS2UaD+6YT00eTsRHjvmZZcp99c4sv5a3V0++LUbvnuB00j3uHz90s7cvefOMZvu8OTw1uFdzrDpoqY3UjnUo6NsVLQTfqPL22Uud7nyAtm0eaPKV5bm6Oxk+e4CmwLzz7PI23yHHZWuOvxYKs2+iUKiUtRPZI7EJkgsQuRCZI7EJkgsQuRCZI7EJkgsQuRCb01Wd3dxRF2lOu1HjJ5JGRdGvkeoO30F1ZDrzLIN+9TjzddpuPrfElAOgEedtl0E56M5mUCIxP8VLPURXr9U2+BqDS4HO/bjpd7rkd/N/PXLpE4zbG12Xcdvu5dPDiRTr2X//tX2j81Ft2rcL2aypV3ma7TlphW4O/YDqV9NgKad+tM7sQmSCxC5EJErsQmSCxC5EJErsQmSCxC5EJErsQmdBXn90qFYyMTSTjrB42AIB4iFXiWwLA+AT3ZEdHeW704mK6xvnCQroNNQCMjfE1AGPBvltt7nWPTR5Nxl7+ZbptMQAgaDcdHZcaeU4A4ATx2VebvFb/qwsLNN6Y5vnwx85cn4xduTpPxx49epTG19f53EeDHghOvHInbZcBoCzTzxkbqjO7EJkgsQuRCRK7EJkgsQuRCRK7EJkgsQuRCRK7EJmwl/7sNwD4JoAZAA7ggrt/2czuB/AXAF7rPvRz7v4I21alUsEIyUGO6qfX6+k830lSIxwAjhzhNchPnU77wQDgSHubzY01OhZB//ZqlecvRz79xER67UI96FvfInX8AaC5yXuFs/oEALDVTB+3MjjVeIU/Z0ePHaPxDVZfPVrTEWG9jTdPj7egygCP99afvQDwGXd/wsymAPzCzB7txr7k7n+zh20IIQbMXvqzzwGY695eNbPnAJw97IkJIQ6W3+k7u5ndBOBdAH7WveuTZvaUmT1oZrt+pjKz82Y2a2azGxu85Y4Q4vDYs9jNbBLA9wB82t1XAHwVwNsA3IbtM/8Xdhvn7hfc/Zy7n4u+ewohDo89id3M6tgW+rfc/fsA4O7z7l66ewfA1wDccXjTFEL0Sih2MzMAXwfwnLt/ccf9p3c87EMAeLlOIcRA2cvV+HcD+CiAp83sye59nwNwr5ndhu1r/S8B+Hi0ITNDnbRlLkr+nb5STVsxE0HJ5MiaO33tFI23WulyzktL6fRXILbOJie4Pba1xe2vI0enk7FxYssBsQXVbvN9l6RFMAAsLK8kY7UgfbYTtGyeOsqtt/n5dBrr5ma6ZTIAdDyyS/ncQKy17h6C+MGzl6vxPwV2LUxOPXUhxHChFXRCZILELkQmSOxCZILELkQmSOxCZILELkQm9LWUNGDYXqOTiJJYFK/V+PtWVBI5KjU9Np4ePzLKD+PpMydpvBH0dF5eXqbxSp2UJQ5KPVdrfO5sbQMA1OrpNtoAsNpK++ys9TAAtAvuRUdzuzz3ajK23uSpvVE551owd+M2PT3LsvTX7bEsPXZ/+xRC/B4hsQuRCRK7EJkgsQuRCRK7EJkgsQuRCRK7EJlgkZ94oDszew3AyzvuOgHg9b5N4HdjWOc2rPMCNLf9cpBzu9Hdr9st0Fex/9bOzWbd/dzAJkAY1rkN67wAzW2/9Gtu+hgvRCZI7EJkwqDFfmHA+2cM69yGdV6A5rZf+jK3gX5nF0L0j0Gf2YUQfUJiFyITBiJ2M7vLzJ43s0tm9tlBzCGFmb1kZk+b2ZNmNjvguTxoZlfN7OKO+46b2aNm9kL3Ny+e3t+53W9ml7vH7kkzu3tAc7vBzH5iZs+a2TNm9qnu/QM9dmRefTluff/ObmZVAP8D4M8AvALg5wDudfdn+zqRBGb2EoBz7j7wBRhm9icA1gB8093f0b3vrwEsuvsD3TfKY+7+l0Myt/sBrA26jXe3W9HpnW3GAXwQwJ9jgMeOzOvD6MNxG8SZ/Q4Al9z9RXdvAfgOgHsGMI+hx90fB/DmdjP3AHioe/shbL9Y+k5ibkOBu8+5+xPd26sA3mgzPtBjR+bVFwYh9rMAfrXj71cwXP3eHcCPzOwXZnZ+0JPZhRl3n+vevgJgZpCT2YWwjXc/eVOb8aE5dvtpf94rukD327zH3f8IwAcAfKL7cXUo8e3vYMPkne6pjXe/2KXN+K8Z5LHbb/vzXhmE2C8DuGHH39d37xsK3P1y9/dVAD/A8LWinn+jg27399UBz+fXDFMb793ajGMIjt0g258PQuw/B3CLmd1sZg0AHwHw8ADm8VuY2UT3wgnMbALA+zF8ragfBnBf9/Z9AH44wLn8BsPSxjvVZhwDPnYDb3/u7n3/AXA3tq/I/y+AvxrEHBLzeiuA/+r+PDPouQH4NrY/1rWxfW3jYwDeAuAxAC8A+E8Ax4dobv8E4GkAT2FbWKcHNLf3YPsj+lMAnuz+3D3oY0fm1ZfjpuWyQmSCLtAJkQkSuxCZILELkQkSuxCZILELkQkSuxCZILELkQn/D8DyI/HhogQ4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8371a1",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c32cc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 3,577,603\n",
      "Trainable params: 3,577,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/13\n",
      "207/207 [==============================] - 1s 5ms/step - loss: 3.8432 - accuracy: 0.5074\n",
      "Epoch 2/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.7495 - accuracy: 0.6408\n",
      "Epoch 3/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.5720 - accuracy: 0.7489\n",
      "Epoch 4/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.4074 - accuracy: 0.8420\n",
      "Epoch 5/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.2209 - accuracy: 0.9202\n",
      "Epoch 6/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.1677 - accuracy: 0.9397\n",
      "Epoch 7/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9660\n",
      "Epoch 8/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9734\n",
      "Epoch 9/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9728\n",
      "Epoch 10/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0566 - accuracy: 0.9817\n",
      "Epoch 11/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.1315 - accuracy: 0.9604\n",
      "Epoch 12/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9856\n",
      "Epoch 13/13\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9924\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               3277312   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 3,577,603\n",
      "Trainable params: 3,577,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(128, (3,3), activation = 'relu', input_shape = (28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation = 'relu'))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(3, activation = 'softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "#model.fit(x_train, y_train, epochs=10)\n",
    "#model.fit(x_train, y_train, epochs=6)\n",
    "model.fit(x_train, y_train, epochs=13)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c54dee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "207/207 [==============================] - 1s 5ms/step - loss: 0.0864 - accuracy: 0.9732\n",
      "Epoch 2/6\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0703 - accuracy: 0.9797\n",
      "Epoch 3/6\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9803\n",
      "Epoch 4/6\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9852\n",
      "Epoch 5/6\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0565 - accuracy: 0.9849\n",
      "Epoch 6/6\n",
      "207/207 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6dd28e9610>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "#model.fit(x_train, y_train, epochs=10)\n",
    "#model.fit(x_train, y_train, epochs=8)\n",
    "model.fit(x_train, y_train, epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11158dc2",
   "metadata": {},
   "source": [
    "# 테스트(검증)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faab900a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "    images=glob.glob(img_path + \"/*.jpg\")\n",
    "    print(len(images), \" images to be resized.\")\n",
    "    target_size=(28,28)\n",
    "    \n",
    "    for img in images:\n",
    "        old_img=Image.open(img)\n",
    "        new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "        new_img.save(img, \"JPEG\")\n",
    "    print(len(images), \" images resized.\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor/\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeca7f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d66747b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28c48dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=300):\n",
    "    img_size=28\n",
    "    color=3\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 \n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img   \n",
    "        labels[idx]=1   # 바위\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img  \n",
    "        labels[idx]=2   # 보 \n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78536158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.1324 - accuracy: 0.6433\n",
      "test_loss:1.1324288845062256\n",
      "test_accuracy : 0.6433333158493042\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test,y_test, verbose = 2)\n",
    "\n",
    "print('test_loss:{}'.format(test_loss))\n",
    "print('test_accuracy : {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae75a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ded08",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eaa3ff",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "첫 익스플로레이션은 'RockScissorPaper'과 '인공지능'에 관해 다뤘습니다.\n",
    "\n",
    "우선 AI전문가가 되기 위한 첫 발자국으로 익숙하지 않은 것을 해본다는 것에서 재밌게 작업했습니다.\n",
    "하지만, 모르는 부분에 있어 단순히 복사-붙여넣기 일명 복붙이 아니라 최대한 배우려고\n",
    "노력했습니다.\n",
    "\n",
    "그러다 보니 5번은 다시 한 것같은데 결론적으로 64.3%정도로 정확도가 나왔습니다.\n",
    "처음 정확도가 24%정도 였고 34%, 46% 54%를 거쳐서 이룬 성과다 보니 꽤 만족했습니다.\n",
    "\n",
    "먼저, 24%의 정확도가 나왔던 이유는 데이터의 양이 너무나도 부족했기 때문이었습니다.\n",
    "연습용으로 300장, 테스트용으로 100장을 이용했습니다.\n",
    "이에 팀원들의 피드백을 듣고서 양을 늘리게 되었습니다.\n",
    "\n",
    "34%를 달성했을 때는 900장의 연습용과 300장의 테스트용을 활용했습니다.\n",
    "여전히 학습 데이터가 부족했다고 판단한여 한 번 더 진행했습니다.\n",
    "\n",
    "46%에는 호기심이 생겼습니다.\n",
    "그래서 연습용 데이터에 900장만 넣어보고 테스트용 데이터에는 4400장이나 넣어봤습니다.\n",
    "예상으로는 크게 차이가 없을 줄 알았지만, 실제로는 낮은 정확도를 띄었습니다.\n",
    "이때 8:2정도의 비율이 좋다는 것도 배울 수 있었고, 한 번 더 연습의 기회가 되었습니다.\n",
    "\n",
    "54%가 나왔을 때는 조금 지쳐있었기에 각각 2000장과 300장 정도를 이용해 진행했습니다.\n",
    "역시 60%의 정확도에 미치지 못했지만, 어떻게 보면 이것 또한 실험었다고 생각합니다.\n",
    "\n",
    "결국에는 64.3%가 나왔습니다.\n",
    "종합적으로 목표를 달성하는 과정에서 resize, 이미지 개수, colour, epoch 등에 관한 실수도 했습니다.\n",
    "다만, 흔히 사용하지만 저는 최근에야 들어본 '백문이 불여일타'라는 가치를 알았고, 실수로써 디테일을 배울 수 있었습니다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
